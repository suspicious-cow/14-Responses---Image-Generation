{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation\n",
    "\n",
    "## Creating the Connection\n",
    "\n",
    "### Importing OpenAI and Initializing the Client\n",
    "\n",
    "To begin, we'll import the `OpenAI` class from the `openai` library, which allows us to interact with the OpenAI API. Next, we initialize a client instance, which we'll use to send requests and receive responses from the OpenAI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is a simple example of using the OpenAI API\n",
    "It uses the OpenAI Python client library to open a connection to the OpenAI API.\n",
    "This also looks for the OPENAI_API_KEY environment variable to authenticate the client.\n",
    "\"\"\"\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra packages to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display, HTML, update_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Search\n",
    "Using the Responses API, you can enable web search by configuring it in the tools array in an API request to generate content. Like any other tool, the model can choose to search the web or not based on the content of the input prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of April 13, 2025, a significant positive development is the agreement between Israel and Hamas on a ceasefire and hostage release deal, aiming to halt a conflict that has resulted in over 46,000 Palestinian deaths over the past 15 months. The ceasefire is set to commence today and last for an initial six weeks. While its durability remains uncertain, human rights agencies have cautiously welcomed the agreement and urged all parties to adhere to its terms. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-03-of-2025/?utm_source=openai)) "
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    input=\"What was a positive news story from today? give me a one paragraph summary and a link to the story.\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in response:  \n",
    "    if event.type == \"response.output_text.delta\": \n",
    "        print(event.delta, end='', flush=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output and Citations\n",
    "\n",
    "Model responses that use the web search tool will include two parts:\n",
    "\n",
    "1. A `web_search_call` output item with the ID of the search call.\n",
    "2. A `message` output item containing:\n",
    "   - The text result in `message.content[0].text`\n",
    "   - Annotations `message.content[0].annotations` for the cited URLs\n",
    "\n",
    "By default, the model's response will include inline citations for URLs found in the web search results. In addition to this, the `url_citation` annotation object will contain the URL, title and location of the cited source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='max-width:100%; overflow-wrap: break-word; white-space: pre-wrap;'>In April 2025, U.S. consumer sentiment sharply declined for the fourth consecutive month, with the University of Michigan's index dropping 11% to 50.8â€”its lowest since the COVID-19 pandemic. The plunge is attributed largely to public concerns over President Donald Trump's aggressive trade war policies, which have sparked fears of job losses and rising inflation. Trump's tariffs include a baseline 10% rate for most countries, with much higher rates for imports from China (145%), Canada, and Mexico (up to 25%). China retaliated with a 125% tariff on U.S. goods. Consequently, sentiment has dropped across all demographics and political affiliations, and expectations for rising unemployment are at their highest since 2009. Inflation expectations have also surged to 4.4%, worrying economists and the Federal Reserve. Financial markets reflect the instability, with Treasury yields rising and the dollar falling. Despite White House calls for public trust, experts warn of a potential recession. Confidence erosion and hiring freezes could further restrain consumer spending, traditionally driven by strong labor markets. ([apnews.com](https://apnews.com/article/fda8125b8b8f4929b1528046d842758f?utm_source=openai))\n",
       "\n",
       "\n",
       "## Recent Developments in the U.S. Economy:\n",
       "- [Potential impact of Trump's trade war on jobs and inflation sends US consumer sentiment plunging](https://apnews.com/article/fda8125b8b8f4929b1528046d842758f?utm_source=openai)\n",
       "- [Trump disrupts global economic order even though the US is dominant](https://apnews.com/article/e532f95f05cf929b7bf27ea636627937?utm_source=openai)\n",
       "- [Blackrock's Larry Fink says economy weakening, CEOs see recession](https://www.axios.com/2025/04/07/larry-fink-recession-economy-tariffs?utm_source=openai) </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define the prompt.\n",
    "prompt = \"Give me the first paragraph of one recent article about the US economy.\"\n",
    "\n",
    "# Create the streaming response.\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    input=prompt,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Initialize an empty string to hold the streamed text.\n",
    "story_text = \"\"\n",
    "\n",
    "# Create a single HTML display cell with styles to auto-wrap text.\n",
    "# 'overflow-wrap: break-word;' and 'white-space: pre-wrap;' ensure the text fits the screen.\n",
    "display_handle = display(\n",
    "    HTML(\"<div style='max-width:100%; overflow-wrap: break-word; white-space: pre-wrap;'></div>\"),\n",
    "    display_id=True\n",
    ")\n",
    "\n",
    "# Process and stream each incoming event.\n",
    "for event in response:\n",
    "    if event.type == \"response.output_text.delta\":\n",
    "        # If event.delta is a dict, extract the text; otherwise assume it's a plain string.\n",
    "        chunk = event.delta.get(\"text\", \"\") if isinstance(event.delta, dict) else event.delta\n",
    "        story_text += chunk\n",
    "\n",
    "        # Build the new HTML content.\n",
    "        html_content = f\"<div style='max-width:100%; overflow-wrap: break-word; white-space: pre-wrap;'>{story_text}</div>\"\n",
    "\n",
    "        # Update the same display cell with the new content.\n",
    "        update_display(HTML(html_content), display_id=display_handle.display_id)\n",
    "        \n",
    "        # (Optional) Small pause to give the cell time to update and the user to read the text as it is produced\n",
    "        # time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Data\n",
    "\n",
    "To refine search results based on geography, you can specify an approximate user location using country, city, region, and/or timezone.\n",
    "\n",
    "- The `type` field is fixed at \"approximate\".\n",
    "- The `city` and `region` fields are free text strings, like Minneapolis and Minnesota respectively.\n",
    "- The `country` field is a two-letter ISO country code, like US.\n",
    "- The `timezone` field is an IANA timezone like America/Chicago.\n",
    "\n",
    "ISO Country Codes:\n",
    "- [ISO 3166-1 alpha-2 Codes](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2)\n",
    "\n",
    "IANA Time Zones:\n",
    "- [List of TZ time zones](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story Summary:\n",
      "\n",
      "As of Sunday, April 13, 2025, at 09:19:58 AM CDT, here's the first paragraph of a recent article from your area:\n",
      "\n",
      "\"Tyler Anderson delivered a stellar performance, taking a no-hitter into the sixth inning and helping the Los Angeles Angels defeat the Houston Astros 4-1 on Saturday.\" ([reuters.com](https://www.reuters.com/sports/baseball/tyler-anderson-sparkles-angels-pound-two-homers-win-over-astros-2025-04-13/?utm_source=openai))\n",
      "\n",
      "Raw Annotations:\n",
      "AnnotationURLCitation(end_index=433, start_index=283, title='Tyler Anderson sparkles, Angels pound 2 HRs in win over Astros', type='url_citation', url='https://www.reuters.com/sports/baseball/tyler-anderson-sparkles-angels-pound-two-homers-win-over-astros-2025-04-13/?utm_source=openai')\n"
     ]
    }
   ],
   "source": [
    "# Define a basic prompt.\n",
    "prompt = (\n",
    "    \"Search the web and give me the first paragraph of one recent article from my area. Make sure to include the curerrent date and time before the article.\"\n",
    ")\n",
    "\n",
    "# Create the streaming response.\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\n",
    "        \"type\": \"web_search_preview\",\n",
    "        \"user_location\": {\n",
    "            \"type\": \"approximate\",\n",
    "            \"country\": \"US\",\n",
    "            \"city\": \"Houston\",\n",
    "            \"region\": \"Texas\",\n",
    "            \"timezone\": \"America/Chicago\",\n",
    "        }\n",
    "    }],\n",
    "    input=prompt,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "story_text = \"\"\n",
    "annotations = []  # We'll collect raw annotation objects here.\n",
    "\n",
    "# Process each event from the response.\n",
    "for event in response:\n",
    "    # For text delta events (which deliver parts of the story text)\n",
    "    if event.type == \"response.output_text.delta\":\n",
    "        delta = event.delta\n",
    "        # If delta is a dict, it may contain text and annotations.\n",
    "        if isinstance(delta, dict):\n",
    "            story_text += delta.get(\"text\", \"\")\n",
    "            # If the delta includes annotations, add them.\n",
    "            if \"annotations\" in delta:\n",
    "                annotations.extend(delta[\"annotations\"])\n",
    "        else:\n",
    "            story_text += delta\n",
    "\n",
    "    # Some annotation events come separately.\n",
    "    elif event.type == \"response.output_text.annotation.added\":\n",
    "        # These events include an 'annotation' attribute.\n",
    "        annotations.append(event.annotation)\n",
    "\n",
    "# Optionally, sort annotations by their starting index.\n",
    "annotations.sort(key=lambda ann: ann.start_index if hasattr(ann, 'start_index') else 0)\n",
    "\n",
    "# Print the final raw story text.\n",
    "print(\"Story Summary:\\n\")\n",
    "print(story_text.strip())\n",
    "\n",
    "# Print the raw annotation objects.\n",
    "print(\"\\nRaw Annotations:\")\n",
    "for ann in annotations:\n",
    "    # Print the entire annotation as a Python dictionary.\n",
    "    print(ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='max-width:100%; overflow-wrap: break-word; white-space: pre-wrap;'>\n",
       "        As of Sunday, April 13, 2025, at 09:43:42 AM CDT, here is the first paragraph of a recent article from your area:\n",
       "\n",
       "\"Tyler Anderson delivered a stellar performance, taking a no-hitter into the sixth inning and helping the Los Angeles Angels defeat the Houston Astros 4-1 on Saturday.\" ([reuters.com](https://www.reuters.com/sports/baseball/tyler-anderson-sparkles-angels-pound-two-homers-win-over-astros-2025-04-13/?utm_source=openai))\n",
       "\n",
       "This article was published today, April 13, 2025. \n",
       "        <hr><strong>Raw Annotations:</strong><br>AnnotationURLCitation(end_index=434, start_index=284, title='Tyler Anderson sparkles, Angels pound 2 HRs in win over Astros', type='url_citation', url='https://www.reuters.com/sports/baseball/tyler-anderson-sparkles-angels-pound-two-homers-win-over-astros-2025-04-13/?utm_source=openai')\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define a basic prompt.\n",
    "prompt = (\n",
    "    \"Search the web and give me the first paragraph of one recent article from my area. Make sure to include the current date and time before the article.\"\n",
    ")\n",
    "\n",
    "# Create the streaming response.\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\n",
    "        \"type\": \"web_search_preview\",\n",
    "        \"user_location\": {\n",
    "            \"type\": \"approximate\",\n",
    "            \"country\": \"US\",\n",
    "            \"city\": \"Houston\",\n",
    "            \"region\": \"Texas\",\n",
    "            \"timezone\": \"America/Chicago\",\n",
    "        }\n",
    "    }],\n",
    "    input=prompt,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Initialize a string to accumulate the story text and a list for annotations.\n",
    "story_text = \"\"\n",
    "annotations = []  \n",
    "\n",
    "# Create a single HTML display cell with CSS for auto-wrapping.\n",
    "display_handle = display(\n",
    "    HTML(\"<div style='max-width:100%; overflow-wrap: break-word; white-space: pre-wrap;'></div>\"),\n",
    "    display_id=True\n",
    ")\n",
    "\n",
    "# Process each incoming event from the streaming response.\n",
    "for event in response:\n",
    "    if event.type == \"response.output_text.delta\":\n",
    "        # If delta is a dict, extract the text and annotations (if any).\n",
    "        if isinstance(event.delta, dict):\n",
    "            text_chunk = event.delta.get(\"text\", \"\")\n",
    "            story_text += text_chunk\n",
    "            if \"annotations\" in event.delta:\n",
    "                annotations.extend(event.delta[\"annotations\"])\n",
    "        else:\n",
    "            # Otherwise, assume delta is just a text string.\n",
    "            story_text += event.delta\n",
    "\n",
    "        # Build updated HTML content that auto-wraps text.\n",
    "        html_content = f\"\"\"\n",
    "        <div style='max-width:100%; overflow-wrap: break-word; white-space: pre-wrap;'>\n",
    "            {story_text}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        # Update the same output cell.\n",
    "        update_display(HTML(html_content), display_id=display_handle.display_id)\n",
    "        \n",
    "        # time.sleep(0.1)  # Optional brief pause for smoother updates.\n",
    "\n",
    "    elif event.type == \"response.output_text.annotation.added\":\n",
    "        annotations.append(event.annotation)\n",
    "\n",
    "# Once streaming has finished, append any annotations at the bottom.\n",
    "if annotations:\n",
    "    annotations_html = \"<hr><strong>Raw Annotations:</strong><br>\" + \"<br>\".join(str(ann) for ann in annotations)\n",
    "    final_html = f\"\"\"\n",
    "    <div style='max-width:100%; overflow-wrap: break-word; white-space: pre-wrap;'>\n",
    "        {story_text}\n",
    "        {annotations_html}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "else:\n",
    "    final_html = f\"\"\"\n",
    "    <div style='max-width:100%; overflow-wrap: break-word; white-space: pre-wrap;'>\n",
    "        {story_text}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# Final update to the same cell with the complete output.\n",
    "update_display(HTML(final_html), display_id=display_handle.display_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Searching\n",
    "\n",
    "## Base64\n",
    "Next, we'll import Python's built-in `base64` library. This module allows us to encode or decode binary data (such as images or files) into a text-based representation, which is often required when working with images in API requests or responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Helper function to encode images in base64\n",
    "# This is necessary because the OpenAI API requires images to be in base64 format\n",
    "# Base64 encoding converts binary image data to a text string that can be safely transmitted\n",
    "def encode_image(image_path):\n",
    "    # Open the image file in binary read mode (\"rb\")\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        # Read the binary data, encode it to base64, and convert to UTF-8 string\n",
    "        # This format is required by the API as part of the data:image/jpeg;base64 URL format\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing a Base64 Encoded Image\n",
    "In the following code cell, we'll use **\"gpt-4o\"** to analyze an image using a Base64 encoded image. The model will examine the picture and generate a descriptive response, which we'll then print out. This demonstrates how AI can interpret visual content alongside text-based instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./artifacts/mystery_gathering.jpg\" width=\"512\" height=\"512\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our image\n",
    "image_path = \"./artifacts/mystery_gathering.jpg\"\n",
    "\n",
    "# Getting the Base64 string - converting the binary image to a text representation\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    # Specify the model to use - gpt-4o-mini is a more efficient version of GPT-4\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            # Define the role of the message sender (user in this case)\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                # The text instruction for the model - what we want it to do with the image\n",
    "                { \"type\": \"input_text\", \"text\": \"Tell me what is in this image.\" },\n",
    "                {\n",
    "                    # The image data being sent to the model via base64 encoding\n",
    "                    # This format allows us to send images from local files rather than URLs\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the model's text response to the console\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detail: Low vs High Resolution\n",
    "The detail parameter tells the model what level of detail to use when processing and understanding the image (low, high, or auto to let the model decide). If you skip the parameter, the model will use auto.\n",
    "\n",
    "### Low Detail\n",
    "You can save tokens and speed up responses by using \"detail\": \"low\". This lets the model process the image with a budget of 85 tokens. The model receives a low-resolution 512px x 512px version of the image. This is fine if your use case doesn't require the model to see with high-resolution detail (for example, if you're asking about the dominant shape or color in the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our image\n",
    "image_path = \"./artifacts/mystery_gathering.jpg\"\n",
    "\n",
    "# Getting the Base64 string - converting the image to base64 format\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    # Using the o1 model (OpenAI's newer model with enhanced vision capabilities)\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            # Set the role to user for this conversation\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                # The text prompt asking for detailed image analysis\n",
    "                { \"type\": \"input_text\", \"text\": \"Tell me all the details you can see in this picture.\" },\n",
    "                {\n",
    "                    # Include the base64-encoded image data\n",
    "                    # The \"detail\":\"low\" parameter tells the model to use low-resolution analysis\n",
    "                    # This saves tokens (85 tokens) and is suitable for basic image understanding\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\":\"low\"\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the model's response to the console\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Detail\n",
    "You can give the model more detail to generate its understanding by using \"detail\": \"high\". This lets the model see the low-resolution image (using 85 tokens) and then creates detailed crops using 170 tokens for each 512px x 512px tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our image\n",
    "image_path = \"./artifacts/mystery_gathering.jpg\"\n",
    "\n",
    "# Getting the Base64 string - converting the image to base64 format\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    # Using the o1 model (OpenAI's advanced vision-capable model)\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            # Set the role to user for this conversation\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                # The text prompt asking for detailed image analysis\n",
    "                { \"type\": \"input_text\", \"text\": \"Tell me all the details you can see in this picture.\" },\n",
    "                {\n",
    "                    # Include the base64-encoded image data\n",
    "                    # The \"detail\":\"high\" parameter tells the model to analyze at high resolution\n",
    "                    # This uses more tokens (85 tokens for low-res overview plus 170 tokens per 512px tile)\n",
    "                    # High detail is useful for reading text, identifying small details, or complex images\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\":\"high\"\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the model's detailed response to the console\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Image Inputs\n",
    "The Responses API can take in and process multiple image inputs. The model processes each image and uses the information to answer questions about all images or each image independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our image\n",
    "image_path = \"./artifacts/mystery_gathering.jpg\"\n",
    "\n",
    "# Getting the Base64 string - converting the image to base64 format\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    # Using gpt-4o-mini for efficient multi-image processing\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            # Set the role to user for this conversation\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                # Ask the model to describe each image with one sentence\n",
    "                { \"type\": \"input_text\", \"text\": \"Give me one sentence describing each image you see.\" },\n",
    "                {\n",
    "                    # First image: local file converted to base64\n",
    "                    # Using low detail to save tokens since we're processing multiple images\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                },\n",
    "                {\n",
    "                # Second image: directly from URL (Taiwan train station)\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/5/53/202412_Taiwan_Railway_Haifeng_EMU500_Tourist_Train_at_Houlong_Station.jpg\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the model's descriptions of both images\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Number of Images\n",
    "\n",
    "### Passing 10 Images\n",
    "\n",
    "Conventional wisdom (and ChatGPT) says you can only pass 10 images at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"./artifacts/mystery_gathering.jpg\" width=\"200\" height=\"200\" alt=\"Image 1\"></td>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/202412_Taiwan_Railway_Haifeng_EMU500_Tourist_Train_at_Houlong_Station.jpg\" width=\"200\" height=\"200\" alt=\"Image 2\"></td>\n",
    "    <td><img src=\"https://plantperfect.com/wp-content/uploads/2021/02/plantperfect_planningyourspringgarden_header.png\" width=\"200\" height=\"200\" alt=\"Image 3\"></td>\n",
    "    <td><img src=\"https://leehamnews.com/wp-content/uploads/2024/04/1379352511007-AP-Canada-Bombardier-CSeries-002-scaled.webp\" width=\"200\" height=\"200\" alt=\"Image 4\"></td>\n",
    "    <td><img src=\"https://cdn.pixabay.com/photo/2021/12/12/20/00/play-6865967_640.jpg\" width=\"200\" height=\"200\" alt=\"Image 5\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"https://thumbs.dreamstime.com/b/obesicat-garden-random-image-fat-pussy-cat-dressed-as-soccer-player-dutch-national-team-exercising-spring-87947898.jpg\" width=\"200\" height=\"200\" alt=\"Image 6\"></td>\n",
    "    <td><img src=\"https://hatrabbits.com/wp-content/uploads/2017/01/tafel-1.jpg\" width=\"200\" height=\"200\" alt=\"Image 7\"></td>\n",
    "    <td><img src=\"https://awkwardfamilyphotos.com/wp-content/uploads/2009/05/IMG_7352-e1458253508588-835x1024.jpg\" width=\"200\" height=\"200\" alt=\"Image 8\"></td>\n",
    "    <td><img src=\"https://i.redd.it/jeuusd992wd41.jpg\" width=\"200\" height=\"200\" alt=\"Image 9\"></td>\n",
    "    <td><img src=\"https://c8.alamy.com/comp/2J53W86/human-brain-with-electric-plug-3d-illustration-2J53W86.jpg\" width=\"200\" height=\"200\" alt=\"Image 10\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our image\n",
    "image_path = \"./artifacts/mystery_gathering.jpg\"\n",
    "\n",
    "# Getting the Base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"input_text\", \"text\": \"Give me one sentence describing each image you see.\" },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\":\"low\"\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/5/53/202412_Taiwan_Railway_Haifeng_EMU500_Tourist_Train_at_Houlong_Station.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://plantperfect.com/wp-content/uploads/2021/02/plantperfect_planningyourspringgarden_header.png\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://leehamnews.com/wp-content/uploads/2024/04/1379352511007-AP-Canada-Bombardier-CSeries-002-scaled.webp\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://cdn.pixabay.com/photo/2021/12/12/20/00/play-6865967_640.jpg\",\n",
    "                },\n",
    "                  {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://thumbs.dreamstime.com/b/obesicat-garden-random-image-fat-pussy-cat-dressed-as-soccer-player-dutch-national-team-exercising-spring-87947898.jpg\",\n",
    "                },\n",
    "                   {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://hatrabbits.com/wp-content/uploads/2017/01/tafel-1.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://awkwardfamilyphotos.com/wp-content/uploads/2009/05/IMG_7352-e1458253508588-835x1024.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://i.redd.it/jeuusd992wd41.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://c8.alamy.com/comp/2J53W86/human-brain-with-electric-plug-3d-illustration-2J53W86.jpg\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing 21 Images\n",
    "Now let's pass 21 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"./artifacts/mystery_gathering.jpg\" width=\"200\" height=\"200\" alt=\"Image 1\"></td>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/202412_Taiwan_Railway_Haifeng_EMU500_Tourist_Train_at_Houlong_Station.jpg\" width=\"200\" height=\"200\" alt=\"Image 2\"></td>\n",
    "    <td><img src=\"https://plantperfect.com/wp-content/uploads/2021/02/plantperfect_planningyourspringgarden_header.png\" width=\"200\" height=\"200\" alt=\"Image 3\"></td>\n",
    "    <td><img src=\"https://leehamnews.com/wp-content/uploads/2024/04/1379352511007-AP-Canada-Bombardier-CSeries-002-scaled.webp\" width=\"200\" height=\"200\" alt=\"Image 4\"></td>\n",
    "    <td><img src=\"https://cdn.pixabay.com/photo/2021/12/12/20/00/play-6865967_640.jpg\" width=\"200\" height=\"200\" alt=\"Image 5\"></td>\n",
    "    <td><img src=\"https://thumbs.dreamstime.com/b/obesicat-garden-random-image-fat-pussy-cat-dressed-as-soccer-player-dutch-national-team-exercising-spring-87947898.jpg\" width=\"200\" height=\"200\" alt=\"Image 6\"></td>\n",
    "    <td><img src=\"https://hatrabbits.com/wp-content/uploads/2017/01/tafel-1.jpg\" width=\"200\" height=\"200\" alt=\"Image 7\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"https://awkwardfamilyphotos.com/wp-content/uploads/2009/05/IMG_7352-e1458253508588-835x1024.jpg\" width=\"200\" height=\"200\" alt=\"Image 8\"></td>\n",
    "    <td><img src=\"https://i.redd.it/jeuusd992wd41.jpg\" width=\"200\" height=\"200\" alt=\"Image 9\"></td>\n",
    "    <td><img src=\"https://c8.alamy.com/comp/2J53W86/human-brain-with-electric-plug-3d-illustration-2J53W86.jpg\" width=\"200\" height=\"200\" alt=\"Image 10\"></td>\n",
    "    <td><img src=\"https://sunshinehouse.com/media/vwrd2hsm/8-random-acts-of-kindness-ideas-for-kids.jpg\" width=\"200\" height=\"200\" alt=\"Image 11\"></td>\n",
    "    <td><img src=\"https://machinelearningmastery.com/wp-content/uploads/2017/01/A-Gentle-Introduction-to-the-Random-Walk-for-Times-Series-Forecasting-with-Python.jpg\" width=\"200\" height=\"200\" alt=\"Image 12\"></td>\n",
    "    <td><img src=\"https://m.media-amazon.com/images/M/MV5BOWM2OWZmMDktOTMyZi00OWRiLWFkZTMtZGZlNTMyYzA0YjI1XkEyXkFqcGdeQXRyYW5zY29kZS13b3JrZmxvdw@@._V1_.jpg\" width=\"200\" height=\"200\" alt=\"Image 13\"></td>\n",
    "    <td><img src=\"https://i.pinimg.com/736x/65/01/2e/65012e67a6c13dd3174d2949bbd815ed.jpg\" width=\"200\" height=\"200\" alt=\"Image 14\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"https://i.pinimg.com/736x/44/8f/57/448f57e6c69f821c1e0295478b1e5a18.jpg\" width=\"200\" height=\"200\" alt=\"Image 15\"></td>\n",
    "    <td><img src=\"https://creator.nightcafe.studio/jobs/tfhWtka8Mb8qxquFAaKZ/tfhWtka8Mb8qxquFAaKZ--1--yljno.jpg\" width=\"200\" height=\"200\" alt=\"Image 16\"></td>\n",
    "    <td><img src=\"https://i.redd.it/gpwe1akq6v7d1.jpeg\" width=\"200\" height=\"200\" alt=\"Image 17\"></td>\n",
    "    <td><img src=\"https://www.randomlists.com/img/animals/snowy_owl.webp\" width=\"200\" height=\"200\" alt=\"Image 18\"></td>\n",
    "    <td><img src=\"https://www.thewordfinder.com/random-animal-generator/images/data_mountaingoat.webp\" width=\"200\" height=\"200\" alt=\"Image 19\"></td>\n",
    "    <td><img src=\"https://www.techtarget.com/rms/onlineImages/GC5A444272_ram_mobile.jpg\" width=\"200\" height=\"200\" alt=\"Image 20\"></td>\n",
    "    <td><img src=\"https://thumbs.dreamstime.com/b/cute-cat-sleeping-street-car-random-58655731.jpg\" width=\"200\" height=\"200\" alt=\"Image 21\"></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our image\n",
    "image_path = \"./artifacts/mystery_gathering.jpg\"\n",
    "\n",
    "# Getting the Base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"input_text\", \"text\": \"Give me one sentence describing each image you see.\" },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\":\"low\"\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/5/53/202412_Taiwan_Railway_Haifeng_EMU500_Tourist_Train_at_Houlong_Station.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://plantperfect.com/wp-content/uploads/2021/02/plantperfect_planningyourspringgarden_header.png\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://leehamnews.com/wp-content/uploads/2024/04/1379352511007-AP-Canada-Bombardier-CSeries-002-scaled.webp\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://cdn.pixabay.com/photo/2021/12/12/20/00/play-6865967_640.jpg\",\n",
    "                },\n",
    "                  {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://thumbs.dreamstime.com/b/obesicat-garden-random-image-fat-pussy-cat-dressed-as-soccer-player-dutch-national-team-exercising-spring-87947898.jpg\",\n",
    "                },\n",
    "                   {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://hatrabbits.com/wp-content/uploads/2017/01/tafel-1.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://awkwardfamilyphotos.com/wp-content/uploads/2009/05/IMG_7352-e1458253508588-835x1024.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://i.redd.it/jeuusd992wd41.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://c8.alamy.com/comp/2J53W86/human-brain-with-electric-plug-3d-illustration-2J53W86.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://sunshinehouse.com/media/vwrd2hsm/8-random-acts-of-kindness-ideas-for-kids.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://machinelearningmastery.com/wp-content/uploads/2017/01/A-Gentle-Introduction-to-the-Random-Walk-for-Times-Series-Forecasting-with-Python.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://m.media-amazon.com/images/M/MV5BOWM2OWZmMDktOTMyZi00OWRiLWFkZTMtZGZlNTMyYzA0YjI1XkEyXkFqcGdeQXRyYW5zY29kZS13b3JrZmxvdw@@._V1_.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://i.pinimg.com/736x/65/01/2e/65012e67a6c13dd3174d2949bbd815ed.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://i.pinimg.com/736x/44/8f/57/448f57e6c69f821c1e0295478b1e5a18.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://creator.nightcafe.studio/jobs/tfhWtka8Mb8qxquFAaKZ/tfhWtka8Mb8qxquFAaKZ--1--yljno.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://i.redd.it/gpwe1akq6v7d1.jpeg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://www.randomlists.com/img/animals/snowy_owl.webp\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://www.thewordfinder.com/random-animal-generator/images/data_mountaingoat.webp\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://www.techtarget.com/rms/onlineImages/GC5A444272_ram_mobile.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://thumbs.dreamstime.com/b/cute-cat-sleeping-street-car-random-58655731.jpg\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can pass as many images as we want as long as we are willing to pay for the tokens. This isn't ChatGPT and you must get out of that mindset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusing Server Errors\n",
    "Now let's pass just four images. We get an error. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our image\n",
    "image_path = \"./artifacts/mystery_gathering.jpg\"\n",
    "\n",
    "# Getting the Base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"input_text\", \"text\": \"Give me one sentence describing each image you see.\" },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\":\"low\"\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/5/53/202412_Taiwan_Railway_Haifeng_EMU500_Tourist_Train_at_Houlong_Station.jpg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://www.bmwgroup.com/en/news/general/2024/humanoid-robots/_jcr_content/newsarticle.coreimg.jpeg/1725965708987/humanoid-robots-2560x896px.jpeg\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://plantperfect.com/wp-content/uploads/2021/02/plantperfect_planningyourspringgarden_header.png\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clue is in the third image URL:\n",
    "\n",
    "https://www.bmwgroup.com/en/news/general/2024/humanoid-robots/_jcr_content/newsarticle.coreimg.jpeg/1725965708987/humanoid-robots-2560x896px.jpeg\n",
    "\n",
    "Look at the size: 2560x896\n",
    "\n",
    "Recall that, even at high resolution, the system will only accept a maximim size of 2000x768\n",
    "\n",
    "So, we are way off on the size and we get some generic message: \"'An error occurred while processing your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists.\"\n",
    "\n",
    "This will cause you to go crazy if you don't know what is going on. Be on the lookout for this 500 error as it usually means you have an image that isn't allowed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
